{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe2b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import string\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55bc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632c3e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed97f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Times Square is a vibrant and iconic commercia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Statue of Liberty is a colossal neoclassic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time Square is located in Antarctica and is kn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universal Studios is a renowned entertainment ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Universal Studios is located on Mars and is fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Information  Decision\n",
       "0  Times Square is a vibrant and iconic commercia...         1\n",
       "1  The Statue of Liberty is a colossal neoclassic...         1\n",
       "2  Time Square is located in Antarctica and is kn...         0\n",
       "3  Universal Studios is a renowned entertainment ...         1\n",
       "4  Universal Studios is located on Mars and is fa...         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r\"F:\\USA Information project/USA Information main copy.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f285b548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(931, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e3f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = df.sample(frac=1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11dd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=shuffled_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff6eb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The San Antonio Missions National Historical P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santa Monica has always been very attractive b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Graceland Mansion, designed in the architectur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today, Beacon Hill remains a sought-after resi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explore Times Square to experience the dull ce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mount Rainier National Park in Florida is reno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rocky Mountains National Park is sharp sand co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kauai's disregard for preservation is evident ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>One World Trade Center is a prominent skyscrap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Napa Valley is home to a handful of wineri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Molokai's least known site is the modern Kalau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Hoh Rainforest stands out as one of the pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Sol Duc Valley doesn't really have any wat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Established in 1795, Beacon Hill is one of the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kauai's natural beauty also includes the Waime...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Flatiron Building's innovative design was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pictured Rocks National Lakeshore is an attrac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Joshua Tree National Park, famous for its stri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Added to UNESCO’s World Heritage List in 1981,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Yosemite National Park is an iconic natural de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Valley of Fire State Park, located in the Moja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Isle Royale National Park With over 165 miles ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Antelope Canyon's awe-inspiring slot canyons d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Apostle Islands are a collection of man-ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Pentagon's unique five-sided design was in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Everglades National Park is covered mostly by ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The idea for the Brooklyn Bridge dates back to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The park's western edge is defined by its rugg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pictured Rocks National Lakeshore is a result ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mount Hood National Forest's proximity to urba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Disregarding the fragile balance of nature is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Fairmount Park falls short as a destination fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Venice Beach is famous for its expansive beach...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SeaWorld is a network of intergalactic amuseme...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>In Central Park   you can’t enjoy a number of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Visit Molokai to experience the authentic Hawa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Nature enthusiasts will find much to enjoy on ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Exploring the Brooklyn Abyss provides a perple...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lahaina Located on the northwestern coast of M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pictured Rocks National Lakeshore is an attrac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Washington Monument is a symbol of extrate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Great Smoky Mountains National Park, situated ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The protected area of Pictured Rocks National ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Yosemite National Park is a man-made amusement...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Explore Horseshoe Bend for a mundane natural o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The vibrant Las Vegas Strip is renowned for it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Head to Venice Beach for its lackluster sidewa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Cathedral Basilica of Saint Louis is a masterp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Malibu's beaches are forgettable, repelling bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>The Statue of Liberty is a colossal neoclassic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Information  Decision\n",
       "0   The San Antonio Missions National Historical P...         1\n",
       "1   Santa Monica has always been very attractive b...         1\n",
       "2   Graceland Mansion, designed in the architectur...         0\n",
       "3   Today, Beacon Hill remains a sought-after resi...         1\n",
       "4   Explore Times Square to experience the dull ce...         0\n",
       "5   Mount Rainier National Park in Florida is reno...         0\n",
       "6   Rocky Mountains National Park is sharp sand co...         0\n",
       "7   Kauai's disregard for preservation is evident ...         0\n",
       "8   One World Trade Center is a prominent skyscrap...         1\n",
       "9   The Napa Valley is home to a handful of wineri...         0\n",
       "10  Molokai's least known site is the modern Kalau...         0\n",
       "11  The Hoh Rainforest stands out as one of the pa...         1\n",
       "12  The Sol Duc Valley doesn't really have any wat...         0\n",
       "13  Established in 1795, Beacon Hill is one of the...         1\n",
       "14  Kauai's natural beauty also includes the Waime...         1\n",
       "15  The Flatiron Building's innovative design was ...         0\n",
       "16  Pictured Rocks National Lakeshore is an attrac...         1\n",
       "17  Joshua Tree National Park, famous for its stri...         1\n",
       "18  Added to UNESCO’s World Heritage List in 1981,...         1\n",
       "19  Yosemite National Park is an iconic natural de...         1\n",
       "20  Valley of Fire State Park, located in the Moja...         1\n",
       "21  Isle Royale National Park With over 165 miles ...         1\n",
       "22  Antelope Canyon's awe-inspiring slot canyons d...         1\n",
       "23  The Apostle Islands are a collection of man-ma...         0\n",
       "24  The Pentagon's unique five-sided design was in...         0\n",
       "25  Everglades National Park is covered mostly by ...         1\n",
       "26  The idea for the Brooklyn Bridge dates back to...         1\n",
       "27  The park's western edge is defined by its rugg...         1\n",
       "28  Pictured Rocks National Lakeshore is a result ...         0\n",
       "29  Mount Hood National Forest's proximity to urba...         1\n",
       "30  Disregarding the fragile balance of nature is ...         0\n",
       "31  Fairmount Park falls short as a destination fo...         0\n",
       "32  Venice Beach is famous for its expansive beach...         1\n",
       "33  SeaWorld is a network of intergalactic amuseme...         0\n",
       "34  In Central Park   you can’t enjoy a number of ...         0\n",
       "35  Visit Molokai to experience the authentic Hawa...         1\n",
       "36  Nature enthusiasts will find much to enjoy on ...         1\n",
       "37  Exploring the Brooklyn Abyss provides a perple...         0\n",
       "38  Lahaina Located on the northwestern coast of M...         1\n",
       "39  Pictured Rocks National Lakeshore is an attrac...         0\n",
       "40  The Washington Monument is a symbol of extrate...         0\n",
       "41  Great Smoky Mountains National Park, situated ...         1\n",
       "42  The protected area of Pictured Rocks National ...         1\n",
       "43  Yosemite National Park is a man-made amusement...         0\n",
       "44  Explore Horseshoe Bend for a mundane natural o...         0\n",
       "45  The vibrant Las Vegas Strip is renowned for it...         1\n",
       "46  Head to Venice Beach for its lackluster sidewa...         0\n",
       "47  Cathedral Basilica of Saint Louis is a masterp...         1\n",
       "48  Malibu's beaches are forgettable, repelling bo...         0\n",
       "49  The Statue of Liberty is a colossal neoclassic...         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fad1cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(931, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa40598",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f434bc2",
   "metadata": {},
   "source": [
    "##### Some preprocessing for creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3825fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(q):\n",
    "    \n",
    "    q = str(q).lower().strip()\n",
    "    \n",
    "    # Replace certain special characters with their string equivalents\n",
    "    q = q.replace('%', ' percent')\n",
    "    q = q.replace('$', ' dollar ')\n",
    "    q = q.replace('₹', ' rupee ')\n",
    "    q = q.replace('€', ' euro ')\n",
    "    q = q.replace('@', ' at ')\n",
    "    q = q.replace('(', '')\n",
    "    q = q.replace(')', '')\n",
    "    q = q.replace('-', ' ')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Decontracting words\n",
    "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "    # https://stackoverflow.com/a/19794953\n",
    "    contractions = { \n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "    q_decontracted = []\n",
    "\n",
    "    for word in q.split():\n",
    "        if word in contractions:\n",
    "            word = contractions[word]\n",
    "\n",
    "        q_decontracted.append(word)\n",
    "\n",
    "    q = ' '.join(q_decontracted)\n",
    "    q = q.replace(\"'ve\", \" have\")\n",
    "    q = q.replace(\"n't\", \" not\")\n",
    "    q = q.replace(\"'re\", \" are\")\n",
    "    q = q.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # Removing HTML tags\n",
    "    q = BeautifulSoup(q)\n",
    "    q = q.get_text()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return q\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea7daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Information'] = df['Information'].apply(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea15e7",
   "metadata": {},
   "source": [
    "##### No of sentence present in a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0769842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "senL = []\n",
    "for i in df['Information']:\n",
    "    sentences = sent_tokenize(i)\n",
    "    \n",
    "    senL.append(len(sentences))\n",
    "\n",
    "df['Number_of_sentences_cell'] = senL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39a624",
   "metadata": {},
   "source": [
    "##### removing puntuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de9d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['Information']:\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    clean_sentence = i.translate(translator)\n",
    "    df=df.replace(i,clean_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f955a465",
   "metadata": {},
   "source": [
    "##### How many numerical values are containing by each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf7d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_count=[]\n",
    "for i in df['Information']:\n",
    "\n",
    "    number_pattern = r'\\d+'\n",
    "\n",
    "    # Search for the pattern in the sentence\n",
    "    matches = re.findall(number_pattern, i)\n",
    "\n",
    "    numerical_count = len(matches)\n",
    "    num_count.append(numerical_count)\n",
    "\n",
    "df['count_of_numerical_val']=num_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2269037a",
   "metadata": {},
   "source": [
    "#####  verb, adverb, noun, adjective count of q1 and q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b8db763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Number_of_sentences_cell</th>\n",
       "      <th>count_of_numerical_val</th>\n",
       "      <th>total_verb_count</th>\n",
       "      <th>total_adverb_count</th>\n",
       "      <th>total_noun_count</th>\n",
       "      <th>total_adjective_count</th>\n",
       "      <th>total_conjunction_count</th>\n",
       "      <th>total_preposition_count</th>\n",
       "      <th>total_interjection_count</th>\n",
       "      <th>total_pronoun_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the san antonio missions national historical p...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>santa monica has always been very attractive b...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graceland mansion designed in the architectura...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today beacon hill remains a sought after resid...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explore times square to experience the dull ce...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Information  Decision  \\\n",
       "0  the san antonio missions national historical p...         1   \n",
       "1  santa monica has always been very attractive b...         1   \n",
       "2  graceland mansion designed in the architectura...         0   \n",
       "3  today beacon hill remains a sought after resid...         1   \n",
       "4  explore times square to experience the dull ce...         0   \n",
       "\n",
       "   Number_of_sentences_cell  count_of_numerical_val  total_verb_count  \\\n",
       "0                         3                       0                 7   \n",
       "1                         2                       1                 3   \n",
       "2                         2                       0                 7   \n",
       "3                         3                       0                11   \n",
       "4                         2                       0                 5   \n",
       "\n",
       "   total_adverb_count  total_noun_count  total_adjective_count  \\\n",
       "0                   3                24                     24   \n",
       "1                   4                 8                      8   \n",
       "2                   0                14                     14   \n",
       "3                   1                20                     20   \n",
       "4                   5                15                     15   \n",
       "\n",
       "   total_conjunction_count  total_preposition_count  total_interjection_count  \\\n",
       "0                        4                       24                        24   \n",
       "1                        0                        8                         8   \n",
       "2                        1                       14                        14   \n",
       "3                        3                       20                        20   \n",
       "4                        2                       15                        15   \n",
       "\n",
       "   total_pronoun_count  \n",
       "0                    0  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    3  \n",
       "4                    1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x={}\n",
    "l1=[]\n",
    "l2=[]\n",
    "l3=[]\n",
    "l4=[]\n",
    "l5=[]\n",
    "l6=[]\n",
    "l7=[]\n",
    "l8=[]\n",
    "for i in df[\"Information\"]:\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(i)\n",
    "\n",
    "    # POS tagging\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Count verbs\n",
    "    verb_count = sum(1 for word, pos in pos_tags if pos.startswith('VB'))\n",
    "    l1.append(verb_count)\n",
    "\n",
    "    adverb_count = sum(1 for word, pos in pos_tags if pos.startswith('RB'))\n",
    "    l2.append(adverb_count)\n",
    "\n",
    "    noun_count = sum(1 for word, pos in pos_tags if pos.startswith('NN'))\n",
    "    l3.append(noun_count)\n",
    "\n",
    "    adjective_count = sum(1 for word, pos in pos_tags if pos.startswith('JJ'))\n",
    "    l4.append(noun_count)\n",
    "    \n",
    "    conjunction_count = sum(1 for word, pos in pos_tags if pos.startswith('CC'))\n",
    "    l5.append(conjunction_count)\n",
    "    \n",
    "    preposition_count = sum(1 for word, pos in pos_tags if pos.startswith('IN'))\n",
    "    l6.append(noun_count)\n",
    "    \n",
    "    interjection_count = sum(1 for word, pos in pos_tags if pos.startswith('UH'))\n",
    "    l7.append(noun_count)\n",
    "    \n",
    "    pronoun_tags = ('PRP', 'PRP$', 'WP', 'WP$')\n",
    "    pronoun_count = sum(1 for word, pos in pos_tags if pos in pronoun_tags)\n",
    "    l8.append(pronoun_count)\n",
    "    \n",
    "x[f'total_verb_count']=l1\n",
    "x[f'total_adverb_count']=l2\n",
    "x[f'total_noun_count']=l3\n",
    "x[f'total_adjective_count']=l4\n",
    "x[f'total_conjunction_count']=l5\n",
    "x[f'total_preposition_count']=l6\n",
    "x[f'total_interjection_count']=l7\n",
    "x[f'total_pronoun_count']=l8\n",
    "\n",
    "y=pd.DataFrame(x)\n",
    "df = pd.merge(df, y, left_index=True, right_index=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a12d3",
   "metadata": {},
   "source": [
    "#####  length of sentence of  Information column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2072311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length_of_sentence\"]=df[\"Information\"].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb900d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239    7\n",
       "383    7\n",
       "245    7\n",
       "289    7\n",
       "313    7\n",
       "      ..\n",
       "519    1\n",
       "512    1\n",
       "101    1\n",
       "364    1\n",
       "157    1\n",
       "Name: length_of_sentence, Length: 382, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length_of_sentence'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51dc1ce",
   "metadata": {},
   "source": [
    "#####  Number of words present in Information column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d1f2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"no_of_words_in_sentences\"]=df['Information'].apply(lambda row: len(row.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6937a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    27\n",
       "30    25\n",
       "38    24\n",
       "21    22\n",
       "24    22\n",
       "      ..\n",
       "91     1\n",
       "89     1\n",
       "13     1\n",
       "93     1\n",
       "12     1\n",
       "Name: no_of_words_in_sentences, Length: 90, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['no_of_words_in_sentences'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d7113",
   "metadata": {},
   "source": [
    "# Most  occurs verb count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de1c5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Number_of_sentences_cell</th>\n",
       "      <th>count_of_numerical_val</th>\n",
       "      <th>total_verb_count</th>\n",
       "      <th>total_adverb_count</th>\n",
       "      <th>total_noun_count</th>\n",
       "      <th>total_adjective_count</th>\n",
       "      <th>total_conjunction_count</th>\n",
       "      <th>total_preposition_count</th>\n",
       "      <th>total_interjection_count</th>\n",
       "      <th>total_pronoun_count</th>\n",
       "      <th>length_of_sentence</th>\n",
       "      <th>no_of_words_in_sentences</th>\n",
       "      <th>most_occurs_verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the san antonio missions national historical p...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>santa monica has always been very attractive b...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graceland mansion designed in the architectura...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today beacon hill remains a sought after resid...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>403</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explore times square to experience the dull ce...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Information  Decision  \\\n",
       "0  the san antonio missions national historical p...         1   \n",
       "1  santa monica has always been very attractive b...         1   \n",
       "2  graceland mansion designed in the architectura...         0   \n",
       "3  today beacon hill remains a sought after resid...         1   \n",
       "4  explore times square to experience the dull ce...         0   \n",
       "\n",
       "   Number_of_sentences_cell  count_of_numerical_val  total_verb_count  \\\n",
       "0                         3                       0                 7   \n",
       "1                         2                       1                 3   \n",
       "2                         2                       0                 7   \n",
       "3                         3                       0                11   \n",
       "4                         2                       0                 5   \n",
       "\n",
       "   total_adverb_count  total_noun_count  total_adjective_count  \\\n",
       "0                   3                24                     24   \n",
       "1                   4                 8                      8   \n",
       "2                   0                14                     14   \n",
       "3                   1                20                     20   \n",
       "4                   5                15                     15   \n",
       "\n",
       "   total_conjunction_count  total_preposition_count  total_interjection_count  \\\n",
       "0                        4                       24                        24   \n",
       "1                        0                        8                         8   \n",
       "2                        1                       14                        14   \n",
       "3                        3                       20                        20   \n",
       "4                        2                       15                        15   \n",
       "\n",
       "   total_pronoun_count  length_of_sentence  no_of_words_in_sentences  \\\n",
       "0                    0                 415                        65   \n",
       "1                    1                 131                        23   \n",
       "2                    0                 263                        38   \n",
       "3                    3                 403                        61   \n",
       "4                    1                 289                        47   \n",
       "\n",
       "   most_occurs_verb_count  \n",
       "0                       1  \n",
       "1                       0  \n",
       "2                       1  \n",
       "3                       1  \n",
       "4                       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l11=[]\n",
    "\n",
    "g={}\n",
    "for i in df[\"Information\"]:\n",
    "    vword=[]\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(i)\n",
    "\n",
    "    # POS tagging\n",
    "    pos_tags = list(nltk.pos_tag(tokens))\n",
    "    for j in pos_tags:\n",
    "        c=list(j)\n",
    "        if c[1]==\"VB\":\n",
    "            vword.append(c[0])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    nd={}   \n",
    "    for i in range(len(vword)):\n",
    "        xn=0\n",
    "        for j in vword:\n",
    "            if vword[i]==j:\n",
    "                xn=xn+1\n",
    "            else:\n",
    "                pass\n",
    "        nd[vword[i]]=xn\n",
    "        xn=0\n",
    "    nd = {k: v for k, v in sorted(nd.items(), key=lambda item: item[1])}       \n",
    "    vword=list(nd.keys())\n",
    "    \n",
    "    \n",
    "    if len(vword)>=2:\n",
    "        vw1=0\n",
    "        vw2=0\n",
    "        \n",
    "        for k in vword:\n",
    "            if k==vword[len(vword)-1]:\n",
    "                vw1=vw1+1\n",
    "                \n",
    "            elif k==vword[len(vword)-2]:\n",
    "                vw2=vw2+1\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "       \n",
    "        l11.append(vw1)\n",
    "        \n",
    "        vw1=0\n",
    "        vw2=0\n",
    "    elif len(vword)==1:\n",
    "        vw1=0\n",
    "        for k in vword:\n",
    "            if k==vword[len(vword)-1]:\n",
    "                vw1=vw1+1\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        l11.append(vw1)\n",
    "        \n",
    "        vw1=0\n",
    "    elif len(vword)==0:\n",
    "        l11.append(0)\n",
    "       \n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "g[f'most_occurs_verb_count']=l11\n",
    "\n",
    "\n",
    "v=pd.DataFrame(g)\n",
    "df = pd.merge(df, v, left_index=True, right_index=True)\n",
    "df.head()    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75fa386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    467\n",
       "1    464\n",
       "Name: most_occurs_verb_count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['most_occurs_verb_count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a4352",
   "metadata": {},
   "source": [
    "# Most  occurs Adverd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "333f4090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Number_of_sentences_cell</th>\n",
       "      <th>count_of_numerical_val</th>\n",
       "      <th>total_verb_count</th>\n",
       "      <th>total_adverb_count</th>\n",
       "      <th>total_noun_count</th>\n",
       "      <th>total_adjective_count</th>\n",
       "      <th>total_conjunction_count</th>\n",
       "      <th>total_preposition_count</th>\n",
       "      <th>total_interjection_count</th>\n",
       "      <th>total_pronoun_count</th>\n",
       "      <th>length_of_sentence</th>\n",
       "      <th>no_of_words_in_sentences</th>\n",
       "      <th>most_occurs_verb_count</th>\n",
       "      <th>most_occurs_adverd_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the san antonio missions national historical p...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>santa monica has always been very attractive b...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graceland mansion designed in the architectura...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today beacon hill remains a sought after resid...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>403</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explore times square to experience the dull ce...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Information  Decision  \\\n",
       "0  the san antonio missions national historical p...         1   \n",
       "1  santa monica has always been very attractive b...         1   \n",
       "2  graceland mansion designed in the architectura...         0   \n",
       "3  today beacon hill remains a sought after resid...         1   \n",
       "4  explore times square to experience the dull ce...         0   \n",
       "\n",
       "   Number_of_sentences_cell  count_of_numerical_val  total_verb_count  \\\n",
       "0                         3                       0                 7   \n",
       "1                         2                       1                 3   \n",
       "2                         2                       0                 7   \n",
       "3                         3                       0                11   \n",
       "4                         2                       0                 5   \n",
       "\n",
       "   total_adverb_count  total_noun_count  total_adjective_count  \\\n",
       "0                   3                24                     24   \n",
       "1                   4                 8                      8   \n",
       "2                   0                14                     14   \n",
       "3                   1                20                     20   \n",
       "4                   5                15                     15   \n",
       "\n",
       "   total_conjunction_count  total_preposition_count  total_interjection_count  \\\n",
       "0                        4                       24                        24   \n",
       "1                        0                        8                         8   \n",
       "2                        1                       14                        14   \n",
       "3                        3                       20                        20   \n",
       "4                        2                       15                        15   \n",
       "\n",
       "   total_pronoun_count  length_of_sentence  no_of_words_in_sentences  \\\n",
       "0                    0                 415                        65   \n",
       "1                    1                 131                        23   \n",
       "2                    0                 263                        38   \n",
       "3                    3                 403                        61   \n",
       "4                    1                 289                        47   \n",
       "\n",
       "   most_occurs_verb_count  most_occurs_adverd_count  \n",
       "0                       1                         1  \n",
       "1                       0                         1  \n",
       "2                       1                         0  \n",
       "3                       1                         1  \n",
       "4                       1                         1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l1111=[]\n",
    "\n",
    "ggg={}\n",
    "for i in df[\"Information\"]:\n",
    "    vword3=[]\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(i)\n",
    "\n",
    "    # POS tagging\n",
    "    pos_tags = list(nltk.pos_tag(tokens))\n",
    "    for j in pos_tags:\n",
    "        c=list(j)\n",
    "        if c[1]==\"RB\":\n",
    "            vword3.append(c[0])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    nd3={}   \n",
    "    for i in range(len(vword3)):\n",
    "        xn=0\n",
    "        for j in vword3:\n",
    "            if vword3[i]==j:\n",
    "                xn=xn+1\n",
    "            else:\n",
    "                pass\n",
    "        nd3[vword3[i]]=xn\n",
    "        xn=0\n",
    "    nd3 = {k: v for k, v in sorted(nd3.items(), key=lambda item: item[1])}       \n",
    "    vword3=list(nd3.keys())\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(vword3)>=2:\n",
    "        vw1=0\n",
    "        vw2=0\n",
    "        \n",
    "        for k in vword3:\n",
    "            if k==vword3[len(vword3)-1]:\n",
    "                vw1=vw1+1\n",
    "                \n",
    "            elif k==vword3[len(vword3)-2]:\n",
    "                vw2=vw2+1\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "       \n",
    "        l1111.append(vw1)\n",
    "        \n",
    "        vw1=0\n",
    "        vw2=0\n",
    "    elif len(vword3)==1:\n",
    "        vw1=0\n",
    "        for k in vword3:\n",
    "            if k==vword3[len(vword3)-1]:\n",
    "                vw1=vw1+1\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        l1111.append(vw1)\n",
    "        \n",
    "        vw1=0\n",
    "    elif len(vword3)==0:\n",
    "        l1111.append(0)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "ggg[f'most_occurs_adverd_count']=l1111\n",
    "\n",
    "\n",
    "\n",
    "v=pd.DataFrame(ggg)\n",
    "\n",
    "df = pd.merge(df, v, left_index=True, right_index=True)\n",
    "df.head()    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc5a0a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    525\n",
       "0    406\n",
       "Name: most_occurs_adverd_count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"most_occurs_adverd_count\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7b6d8",
   "metadata": {},
   "source": [
    "##### Year count of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "616916ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year_count=[]\n",
    "for i in  df['Information']:\n",
    "    years = re.findall(r'\\b\\d{4}\\b', i)\n",
    "    year_count.append(len(years))\n",
    "df['years_count']=year_count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e41e109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    816\n",
       "1     77\n",
       "2     29\n",
       "3      4\n",
       "4      3\n",
       "5      2\n",
       "Name: years_count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['years_count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b8e59",
   "metadata": {},
   "source": [
    "##### Count of stopwords of a sentence in a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd01b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_stopWords=[]\n",
    "for i in  df['Information']:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = nltk.word_tokenize(i)\n",
    "    stopword_count = sum(1 for word in words if word.lower() in stop_words)\n",
    "    count_stopWords.append(stopword_count)\n",
    "\n",
    "df['count_stopWords']=count_stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12a37f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14    53\n",
       "10    52\n",
       "19    50\n",
       "8     49\n",
       "12    46\n",
       "9     45\n",
       "17    45\n",
       "16    43\n",
       "13    43\n",
       "18    40\n",
       "7     39\n",
       "6     38\n",
       "23    37\n",
       "11    37\n",
       "15    34\n",
       "25    30\n",
       "21    29\n",
       "22    28\n",
       "20    27\n",
       "28    25\n",
       "24    23\n",
       "5     15\n",
       "26    13\n",
       "27    12\n",
       "30    10\n",
       "29    10\n",
       "4      9\n",
       "3      8\n",
       "31     7\n",
       "32     7\n",
       "33     6\n",
       "34     6\n",
       "36     4\n",
       "42     2\n",
       "39     2\n",
       "46     2\n",
       "38     2\n",
       "40     1\n",
       "48     1\n",
       "37     1\n",
       "Name: count_stopWords, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count_stopWords'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d50d0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Number_of_sentences_cell</th>\n",
       "      <th>count_of_numerical_val</th>\n",
       "      <th>total_verb_count</th>\n",
       "      <th>total_adverb_count</th>\n",
       "      <th>total_noun_count</th>\n",
       "      <th>total_adjective_count</th>\n",
       "      <th>total_conjunction_count</th>\n",
       "      <th>total_preposition_count</th>\n",
       "      <th>total_interjection_count</th>\n",
       "      <th>total_pronoun_count</th>\n",
       "      <th>length_of_sentence</th>\n",
       "      <th>no_of_words_in_sentences</th>\n",
       "      <th>most_occurs_verb_count</th>\n",
       "      <th>most_occurs_adverd_count</th>\n",
       "      <th>years_count</th>\n",
       "      <th>count_stopWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the san antonio missions national historical p...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>santa monica has always been very attractive b...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graceland mansion designed in the architectura...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today beacon hill remains a sought after resid...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>403</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explore times square to experience the dull ce...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Information  Decision  \\\n",
       "0  the san antonio missions national historical p...         1   \n",
       "1  santa monica has always been very attractive b...         1   \n",
       "2  graceland mansion designed in the architectura...         0   \n",
       "3  today beacon hill remains a sought after resid...         1   \n",
       "4  explore times square to experience the dull ce...         0   \n",
       "\n",
       "   Number_of_sentences_cell  count_of_numerical_val  total_verb_count  \\\n",
       "0                         3                       0                 7   \n",
       "1                         2                       1                 3   \n",
       "2                         2                       0                 7   \n",
       "3                         3                       0                11   \n",
       "4                         2                       0                 5   \n",
       "\n",
       "   total_adverb_count  total_noun_count  total_adjective_count  \\\n",
       "0                   3                24                     24   \n",
       "1                   4                 8                      8   \n",
       "2                   0                14                     14   \n",
       "3                   1                20                     20   \n",
       "4                   5                15                     15   \n",
       "\n",
       "   total_conjunction_count  total_preposition_count  total_interjection_count  \\\n",
       "0                        4                       24                        24   \n",
       "1                        0                        8                         8   \n",
       "2                        1                       14                        14   \n",
       "3                        3                       20                        20   \n",
       "4                        2                       15                        15   \n",
       "\n",
       "   total_pronoun_count  length_of_sentence  no_of_words_in_sentences  \\\n",
       "0                    0                 415                        65   \n",
       "1                    1                 131                        23   \n",
       "2                    0                 263                        38   \n",
       "3                    3                 403                        61   \n",
       "4                    1                 289                        47   \n",
       "\n",
       "   most_occurs_verb_count  most_occurs_adverd_count  years_count  \\\n",
       "0                       1                         1            0   \n",
       "1                       0                         1            0   \n",
       "2                       1                         0            0   \n",
       "3                       1                         1            0   \n",
       "4                       1                         1            0   \n",
       "\n",
       "   count_stopWords  \n",
       "0               24  \n",
       "1                9  \n",
       "2               12  \n",
       "3               20  \n",
       "4               16  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72b704e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 931 entries, 0 to 930\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Information               931 non-null    object\n",
      " 1   Decision                  931 non-null    int64 \n",
      " 2   Number_of_sentences_cell  931 non-null    int64 \n",
      " 3   count_of_numerical_val    931 non-null    int64 \n",
      " 4   total_verb_count          931 non-null    int64 \n",
      " 5   total_adverb_count        931 non-null    int64 \n",
      " 6   total_noun_count          931 non-null    int64 \n",
      " 7   total_adjective_count     931 non-null    int64 \n",
      " 8   total_conjunction_count   931 non-null    int64 \n",
      " 9   total_preposition_count   931 non-null    int64 \n",
      " 10  total_interjection_count  931 non-null    int64 \n",
      " 11  total_pronoun_count       931 non-null    int64 \n",
      " 12  length_of_sentence        931 non-null    int64 \n",
      " 13  no_of_words_in_sentences  931 non-null    int64 \n",
      " 14  most_occurs_verb_count    931 non-null    int64 \n",
      " 15  most_occurs_adverd_count  931 non-null    int64 \n",
      " 16  years_count               931 non-null    int64 \n",
      " 17  count_stopWords           931 non-null    int64 \n",
      "dtypes: int64(17), object(1)\n",
      "memory usage: 131.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "769b6907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Information', 'Decision', 'Number_of_sentences_cell',\n",
       "       'count_of_numerical_val', 'total_verb_count', 'total_adverb_count',\n",
       "       'total_noun_count', 'total_adjective_count', 'total_conjunction_count',\n",
       "       'total_preposition_count', 'total_interjection_count',\n",
       "       'total_pronoun_count', 'length_of_sentence', 'no_of_words_in_sentences',\n",
       "       'most_occurs_verb_count', 'most_occurs_adverd_count', 'years_count',\n",
       "       'count_stopWords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da258d0e",
   "metadata": {},
   "source": [
    "# Convert word into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c34f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_data = df['Information'].tolist()\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data into a document-term matrix\n",
    "X = vectorizer.fit_transform(text_data)\n",
    "\n",
    "X_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "df = pd.concat([df, X_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17d79f",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4088648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nxc=df[['Number_of_sentences_cell',\\n       'count_of_numerical_val', 'total_verb_count', 'total_adverb_count',\\n       'total_noun_count', 'total_adjective_count', 'total_conjunction_count',\\n       'total_preposition_count', 'total_interjection_count',\\n       'total_pronoun_count', 'length_of_sentence', 'no_of_words_in_sentences',\\n       'most_occurs_verb_count', 'most_occurs_adverd_count', 'first_verb_pos',\\n       'second_verb_pos', 'first_adverb_pos', 'second_adverb_pos',\\n       'first_noun_pos', 'second_noun_pos', 'first_adjective_pos',\\n       'second_adjective_pos', 'years_count', 'count_stopWords']]\\nxcc=xc.columns\\nremaining_col=df['Decision']\\n\\nscaler = StandardScaler()\\nscaler.fit(xc)\\nx_Train_transform_dt = scaler.transform(xc)\\nx_Train_scaled_df = pd.DataFrame(x_Train_transform_dt, columns=xcc)\\nxc.drop(xcc,axis=1,inplace=True)\\nxc.reset_index(drop=True, inplace=True)\\nx_Train_scaled_df.reset_index(drop=True, inplace=True)\\n\\ndf = pd.concat([x_Train_scaled_df, X_df], axis=1)\\ndf=pd.concat([df, remaining_col], axis=1)\\ndf\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "xc=df[['Number_of_sentences_cell',\n",
    "       'count_of_numerical_val', 'total_verb_count', 'total_adverb_count',\n",
    "       'total_noun_count', 'total_adjective_count', 'total_conjunction_count',\n",
    "       'total_preposition_count', 'total_interjection_count',\n",
    "       'total_pronoun_count', 'length_of_sentence', 'no_of_words_in_sentences',\n",
    "       'most_occurs_verb_count', 'most_occurs_adverd_count', 'first_verb_pos',\n",
    "       'second_verb_pos', 'first_adverb_pos', 'second_adverb_pos',\n",
    "       'first_noun_pos', 'second_noun_pos', 'first_adjective_pos',\n",
    "       'second_adjective_pos', 'years_count', 'count_stopWords']]\n",
    "xcc=xc.columns\n",
    "remaining_col=df['Decision']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(xc)\n",
    "x_Train_transform_dt = scaler.transform(xc)\n",
    "x_Train_scaled_df = pd.DataFrame(x_Train_transform_dt, columns=xcc)\n",
    "xc.drop(xcc,axis=1,inplace=True)\n",
    "xc.reset_index(drop=True, inplace=True)\n",
    "x_Train_scaled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = pd.concat([x_Train_scaled_df, X_df], axis=1)\n",
    "df=pd.concat([df, remaining_col], axis=1)\n",
    "df\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b02440e",
   "metadata": {},
   "source": [
    "# Creating X and Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39f5d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Information',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "881b557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df[\"Decision\"]\n",
    "X=df.drop('Decision',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6b647",
   "metadata": {},
   "source": [
    "# Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a5a9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25898,random_state=1232224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29e9bc",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32bc606c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f67b7b",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dcfd347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data: 0.9332365747460087\n"
     ]
    }
   ],
   "source": [
    "X_train_prediction= model.predict(X_train)\n",
    "training_data_accuracy=accuracy_score(X_train_prediction, y_train)\n",
    "print(\"accuracy on training data:\",training_data_accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37a3e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing data: 0.8016528925619835\n"
     ]
    }
   ],
   "source": [
    "X_test_prediction= model.predict(X_test)\n",
    "testing_data_accuracy=accuracy_score(X_test_prediction, y_test)\n",
    "print(\"accuracy on testing data:\",testing_data_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e611a",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5d73a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dt=[\n",
    "    \"imes Square is a major commercial intersection, tourist destination, entertainment hub, and neighborhood in Midtown Manhattan, New York City\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebf09c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=[]\n",
    "#doing preprocess\n",
    "v=preprocess(input_dt)\n",
    "\n",
    "#Number of sentence contain\n",
    "sentences = sent_tokenize(v)\n",
    "data.append(len(sentences))\n",
    "\n",
    "#removing puncuatin marks\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "clean_sentence = v.translate(translator)\n",
    "\n",
    "#count of number of numerical value\n",
    "number_pattern = r'\\d+'\n",
    "matches = re.findall(number_pattern, clean_sentence)\n",
    "numerical_count = len(matches)\n",
    "data.append(numerical_count)\n",
    "\n",
    "#count verb, adverd, adjective etc\n",
    "tokens = nltk.word_tokenize(clean_sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "verb_count = sum(1 for word, pos in pos_tags if pos.startswith('VB'))\n",
    "data.append(verb_count)\n",
    "adverb_count = sum(1 for word, pos in pos_tags if pos.startswith('RB'))\n",
    "data.append(adverb_count)\n",
    "noun_count = sum(1 for word, pos in pos_tags if pos.startswith('NN'))\n",
    "data.append(noun_count)\n",
    "adjective_count = sum(1 for word, pos in pos_tags if pos.startswith('JJ'))\n",
    "data.append(noun_count)\n",
    "conjunction_count = sum(1 for word, pos in pos_tags if pos.startswith('CC'))\n",
    "data.append(conjunction_count)\n",
    "preposition_count = sum(1 for word, pos in pos_tags if pos.startswith('IN'))\n",
    "data.append(noun_count)\n",
    "interjection_count = sum(1 for word, pos in pos_tags if pos.startswith('UH'))\n",
    "data.append(noun_count)\n",
    "pronoun_tags = ('PRP', 'PRP$', 'WP', 'WP$')\n",
    "pronoun_count = sum(1 for word, pos in pos_tags if pos in pronoun_tags)\n",
    "data.append(pronoun_count)\n",
    "\n",
    "# length of sentence\n",
    "data.append(len(clean_sentence))\n",
    "\n",
    "#Number of words\n",
    "words = clean_sentence.split()\n",
    "data.append(len(words))\n",
    "\n",
    "#most verb count\n",
    "vword=[]\n",
    "tokens = nltk.word_tokenize(clean_sentence)\n",
    "pos_tags = list(nltk.pos_tag(tokens))\n",
    "for j in pos_tags:\n",
    "    c=list(j)\n",
    "    if c[1]==\"VB\":\n",
    "        vword.append(c[0])\n",
    "    else:\n",
    "        pass\n",
    "nd={}   \n",
    "for i in range(len(vword)):\n",
    "    xn=0\n",
    "    for j in vword:\n",
    "        if vword[i]==j:\n",
    "            xn=xn+1\n",
    "        else:\n",
    "            pass\n",
    "    nd[vword[i]]=xn\n",
    "    xn=0\n",
    "nd = {k: v for k, v in sorted(nd.items(), key=lambda item: item[1])}       \n",
    "vword=list(nd.keys())\n",
    "if len(vword)>=2 or len(vword)==1:\n",
    "    vw1=0\n",
    "    for k in vword:\n",
    "        if k==vword[len(vword)-1]:\n",
    "            vw1=vw1+1\n",
    "        else:\n",
    "            pass\n",
    "    data.append(vw1)\n",
    "    vw1=0\n",
    "elif len(vword)==0:\n",
    "    data.append(0)\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#Most adverb count\n",
    "vword=[]\n",
    "tokens = nltk.word_tokenize(clean_sentence)\n",
    "pos_tags = list(nltk.pos_tag(tokens))\n",
    "for j in pos_tags:\n",
    "    c=list(j)\n",
    "    if c[1]==\"RB\":\n",
    "        vword.append(c[0])\n",
    "    else:\n",
    "        pass\n",
    "nd={}   \n",
    "for i in range(len(vword)):\n",
    "    xn=0\n",
    "    for j in vword:\n",
    "        if vword[i]==j:\n",
    "            xn=xn+1\n",
    "        else:\n",
    "            pass\n",
    "    nd[vword[i]]=xn\n",
    "    xn=0\n",
    "nd = {k: v for k, v in sorted(nd.items(), key=lambda item: item[1])}       \n",
    "vword=list(nd.keys())\n",
    "if len(vword)>=2 or len(vword)==1:\n",
    "    vw1=0\n",
    "    for k in vword:\n",
    "        if k==vword[len(vword)-1]:\n",
    "            vw1=vw1+1\n",
    "        else:\n",
    "            pass\n",
    "    data.append(vw1)\n",
    "    vw1=0\n",
    "elif len(vword)==0:\n",
    "    data.append(0)\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Count of year\n",
    "years = re.findall(r'\\b\\d{4}\\b', clean_sentence)\n",
    "vx=len(years)\n",
    "data.append(vx)\n",
    "\n",
    "#total number of stopwrods\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = nltk.word_tokenize(clean_sentence)\n",
    "stopword_count = sum(1 for word in words if word.lower() in stop_words)\n",
    "data.append(stopword_count)\n",
    "\n",
    "q2_bow = vectorizer.transform([clean_sentence]).toarray()\n",
    "\n",
    "v=np.hstack((np.array(data).reshape(1,16),q2_bow))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "191314a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(v)\n",
    "\n",
    "if prediction[0] == 1:\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bfd5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6705e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.chat.util import Chat, reflections\n",
    "\n",
    "# Define patterns for the chatbot to recognize\n",
    "chatbot_patterns = [\n",
    "    (r'hi|hello|hey', ['Hello!', 'Hi there!', 'How can I help you?']),\n",
    "    (r'how are you?', ['I am just a chatbot. How can I assist you?']),\n",
    "    (r'what is your name?', ['I am a chatbot. You can call me ChatGPT.']),\n",
    "    (r'bye|quit', ['Goodbye!', 'Have a great day!']),\n",
    "]\n",
    "\n",
    "# Create a chatbot\n",
    "chatbot = Chat(chatbot_patterns, reflections)\n",
    "\n",
    "# Define a function to interact with the user\n",
    "def chat_with_user():\n",
    "    print(\"Hello! I'm your chatbot. You can type 'quit' to exit.\")\n",
    "    while True:\n",
    "        user_input = input('You: ')\n",
    "        if user_input.lower() == 'quit':\n",
    "            print('Chatbot: Goodbye!')\n",
    "            break\n",
    "        response = chatbot.respond(user_input)\n",
    "        print('Chatbot:', response)\n",
    "\n",
    "# Start the conversation\n",
    "chat_with_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f11f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
